## Introdução
Esse projeto apresenta os códigos, escritos na linguagem de programação Python, desenvolvidos como parte do trabalho de conclusão de curso apresentado pela aluna Rayane de Araújo Nunes ao Curso de Especialização em Ciência de Dados e Big Data como requisito parcial à obtenção do título de especialista. 

Neste repositório, encontram-se os códigos referentes à extração, tratamento e processamento dos dados para análise de tweets referentes ao COVID-19, visando analisar o que as pessoas estavam falando sobre o isolamento social, aplicado como forma de contenção à pandemia.

Para tanto são utilizadas diversas técnicas de Natural Language Processing (NLP) e a clusterização dos dados, através dos modelos de aprendizado não supervisionado K-means e Mini Batch K-means.

## Requisitos
Para conseguir executar os códigos, será necessária a instalação das seguintes tecnologias:
- Python 3+
- Jupyter Notebook

## Configurações
1. Dois Jupyter Notebooks devem ser criados;
2. Os scripts em Python contidos na pasta ```src/``` devem ser copiados, cada um para seu respectivo Jupyter Notebook;
3. Os datasets já extraídos estão contidos na pasta ```dataset/```.

## Construído com

* [Python](https://www.python.org/) 
* [Pandas](https://pandas.pydata.org/)
* [TweetPY](https://www.tweepy.org/)
* [Tweeter API](https://developer.twitter.com/en)
* [Sklearn](https://scikit-learn.org/stable/)
* [NLTK](https://www.nltk.org/)

## Autora

* **Rayane de Araújo Nunes**